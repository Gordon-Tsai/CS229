# -*- coding: utf-8 -*-
"""229-EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rzDcbRiQSUd2Dp2UgaVDmf7WKKWl1tEc
"""

import numpy as np
import pandas as pd   
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
import itertools

from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
#from catboost import CatBoostClassifier
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier

from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder
from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_curve, roc_auc_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier

credit_record = pd.read_csv("/content/drive/MyDrive/CS229/credit_record.csv")
application_record = pd.read_csv("/content/drive/MyDrive/CS229/application_record.csv")

'''
The original application_record consists of 19 features, as follows.
1) ID: The customer ID. We use it for grouping the two files.
2) CODE_GENDER: Male (M) or Female (F). We convert it to a binary variable. 
3) FlAG_OWN_CAR: Whether the person owns a car (Y/N). We convert it to a binary variable. 
4) FlAG_OWN_REALTY: Whether the person owns a Realty (Y/N). We convert it to a binary variable. 
5) CNT_CHILDREN: Number of Children in the family. 
6) AMT_INCOME_TOTAL: Personal income. 
7) NAME_INCOME_TYPE: Working, Commercial associate, Pensioner, State servant, Student. We group together a few occupations, and perform One-Hot Encoding.
8) NAME_EDUCATION_TYPE: Secondary/secondary special, Higher education, Incomplete higher, Lower Secondary, Academic degree. We group together a few Education Types, and perform One-Hot Encoding.
9) NAME_FAMILY_STATUS: Married, Single/not married, Civil marriage, Separated, Widow. We perform One-Hot Encoding
10) NAME_HOUSING_TYPE: House/apartment, With parents, Municipal apartment, Rented apartment, Office apartment. We perform One-Hot Encoding.
11) DAYS_BIRTH: Age. We dropped this variable since it is highly correlated with Days Employed.
12) DAYS_EMPLOYED: How long the person has been employed.
13) FLAG_MOBIL: Whether the customer have a mobile phone (0/1). We dropped this variable as all customers had a mobile phone.
14) FLAG_WORK_PHONE: Whether the customer have a work phone (0/1). We dropped this variable.
15) FLAG_PHONE: Whether the customer have a phone (0/1). We dropped this variable. We created a new binary variable to indicated whether a person has a phone or work phone.
16) FLAG_EMAIL: Whether the person has an email (0/1). We dropped this variable.
17) OCCUPATION_TYPE: Laborers, Core staff, Sales staff, Managers, Drivers. We perform One-Hot Encoding.
18) CNT_FAM_MEMBERS: Count of members in the family
'''

# We first find the users' account open month.
begin_month=pd.DataFrame(credit_record.groupby(["ID"])["MONTHS_BALANCE"].agg(min))
begin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month1'}) 
new_data=pd.merge(application_record,begin_month,how="left",on="ID")

# Define the target/dependent variable
credit_record['temp_value'] = None
credit_record['temp_value'][credit_record['STATUS'] =='1']='Yes' 
credit_record['temp_value'][credit_record['STATUS'] =='2']='Yes' 
credit_record['temp_value'][credit_record['STATUS'] =='3']='Yes' 
credit_record['temp_value'][credit_record['STATUS'] =='4']='Yes' 
credit_record['temp_value'][credit_record['STATUS'] =='5']='Yes'

customer_count=credit_record.groupby('ID').count()
customer_count['temp_value'][customer_count['temp_value'] > 0]='Yes' 
cpunt['temp_value'][customer_count['temp_value'] == 0]='No' 
customer_count = customer_count[['temp_value']]
new_data=pd.merge(new_data,customer_count,how='inner',on='ID')

new_data['target']=new_data['temp_value']
new_data.loc[new_data['target']=='Yes','target']=1
new_data.loc[new_data['target']=='No','target']=0

new_data.drop('temp_value',axis=1,inplace=True)

# ATTEMPTING CORRELATION MATRIX
# correlation analysis with heatmap, after dropping the has a mobile phone with the target feature as int
cc_train_copy_corr_no_mobile = pd.concat([new_data.drop(['FLAG_MOBIL','target'], axis=1),is_high_risk_int],axis=1).corr()
mask = np.zeros_like(cc_train_copy_corr_no_mobile, dtype='bool')
mask[np.triu_indices_from(mask)] = True
fig, ax = plt.subplots(figsize=(18,10))
sns.heatmap(cc_train_copy_corr_no_mobile, annot=True, cmap='flare',mask=mask, linewidths=.5)
plt.show()

# Data Preprocessing
new_data['CODE_GENDER'] = new_data['CODE_GENDER'].replace(['F','M'],[0,1])

# HAVING A CAR OR NOT
new_data['FLAG_OWN_CAR'] = new_data['FLAG_OWN_CAR'].replace(['N','Y'],[0,1])

#HAVING HOUSE REALTY OR NOT
new_data['FLAG_OWN_REALTY'] = new_data['FLAG_OWN_REALTY'].replace(['N','Y'],[0,1])

# HAVING A MOBILE PHONE OR NOT - Dropped

# HAS A PHONE - Dropped

our_phone = ["Own", "Not Own"]

# WORK PHONE - Dropped

new_data["new_phone"] = None
new_data['new_phone'] = np.where(((new_data["FLAG_PHONE"]==1) | (new_data["FLAG_WORK_PHONE"]==1)), 1, 0)

#new_data["new_phone"].sum() # 14381

#EMAIL -- Dropped

# CHILDREN NUMBER

new_data.loc[new_data['CNT_CHILDREN'] >= 2,'CNT_CHILDREN']='2 or More'

new_data = pd.get_dummies(new_data,columns=['CNT_CHILDREN'])

new_data1 = new_data.copy()

# Personal Income
new_data1["AMT_INCOME_TOTAL"].quantile(1/3), new_data1["AMT_INCOME_TOTAL"].quantile(2/3) # (135000, 202500)
new_data1["new_income"] = None

new_data1["new_income"][new_data1["AMT_INCOME_TOTAL"]<135000] = 0
new_data1["new_income"][new_data1["AMT_INCOME_TOTAL"].between(135000,202500)] = 1
new_data1["new_income"][new_data1["AMT_INCOME_TOTAL"]>202500] = 2

new_data1 = pd.get_dummies(new_data1,columns=['new_income'])

# DAYS_BIRTH -- DROP
#new_data1['Age']=-(new_data['DAYS_BIRTH'])//365

# Days Employed
new_data1['worktm']=-(new_data1['DAYS_EMPLOYED'])//365	
new_data1["worktm"].describe()
new_data1.loc[new_data1['worktm']<0,'worktm']=0

new_data1["worktm1"] = None
new_data1["worktm1"][new_data1["worktm"]<5] = 0
new_data1["worktm1"][new_data1["worktm"].between(5,10)] = 1
new_data1["worktm1"][new_data1["worktm"]>10] = 2

new_data1 = pd.get_dummies(new_data1,columns=["worktm1"])

new_data2 = new_data1.copy()

# Income Type
new_data2 = pd.get_dummies(new_data2,columns=['NAME_INCOME_TYPE'])

new_data2["OCCUPATION_TYPE"].fillna(value = "Other", inplace=True) # filling the NaNs in the column with type "Other" based on what we did before the midterm

# Occupation Type
new_data2.loc[(new_data2['OCCUPATION_TYPE']=='Cleaning staff') | (new_data2['OCCUPATION_TYPE']=='Cooking staff') | (new_data2['OCCUPATION_TYPE']=='Drivers') | (new_data2['OCCUPATION_TYPE']=='Laborers') | (new_data2['OCCUPATION_TYPE']=='Low-skill Laborers') | (new_data2['OCCUPATION_TYPE']=='Security staff') | (new_data2['OCCUPATION_TYPE']=='Waiters/barmen staff'),'OCCUPATION_TYPE']='Laborwk'
new_data2.loc[(new_data2['OCCUPATION_TYPE']=='Accountants') | (new_data2['OCCUPATION_TYPE']=='Core staff') | (new_data2['OCCUPATION_TYPE']=='HR staff') | (new_data2['OCCUPATION_TYPE']=='Medicine staff') | (new_data2['OCCUPATION_TYPE']=='Private service staff') | (new_data2['OCCUPATION_TYPE']=='Realty agents') | (new_data2['OCCUPATION_TYPE']=='Sales staff') | (new_data2['OCCUPATION_TYPE']=='Secretaries'),'OCCUPATION_TYPE']='officewk'
new_data2.loc[(new_data2['OCCUPATION_TYPE']=='Managers') | (new_data2['OCCUPATION_TYPE']=='High skill tech staff') | (new_data2['OCCUPATION_TYPE']=='IT staff'),'OCCUPATION_TYPE']='hightecwk'new_data2 = pd.get_dummies(new_data2,columns=['OCCUPATION_TYPE'])
new_data2 = pd.get_dummies(new_data2,columns=['OCCUPATION_TYPE'])

# House Type
new_data2.loc[new_data2['NAME_HOUSING_TYPE']=='Municipal apartment','NAME_HOUSING_TYPE']='apartment'
new_data2.loc[new_data2['NAME_HOUSING_TYPE']=='Rented apartment','NAME_HOUSING_TYPE']='apartment'
new_data2.loc[new_data2['NAME_HOUSING_TYPE']=='Co-op apartment','NAME_HOUSING_TYPE']='apartment'
new_data2.loc[new_data2['NAME_HOUSING_TYPE']=='Office apartment','NAME_HOUSING_TYPE']='apartment'
new_data2 = pd.get_dummies(new_data2,columns=["NAME_HOUSING_TYPE"])

#EDUCATION
new_data3 = new_data2.copy()

new_data3.loc[new_data2['NAME_EDUCATION_TYPE']=='Academic degree','NAME_EDUCATION_TYPE']='Higher education'
new_data3.loc[new_data2['NAME_EDUCATION_TYPE']=='Incomplete higher','NAME_EDUCATION_TYPE'] = 'Secondary / secondary special'
new_data3 = pd.get_dummies(new_data3,columns=["NAME_EDUCATION_TYPE"])

# MARRIAGE CONDITION
new_data3.loc[new_data3['NAME_FAMILY_STATUS']=='Civil marriage','NAME_FAMILY_STATUS']='Married'
new_data3 = pd.get_dummies(new_data3,columns=["NAME_FAMILY_STATUS"])

new_data4 = new_data3.copy()

#FINISHED DATA PREPROCESSING